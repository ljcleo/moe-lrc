{"key": "powermoe", "main": true, "name": "PowerMoE-3B", "abbr": "PW", "type": "causal", "num_params": 3.3, "num_layers": 32, "num_experts": 40, "top_k": 8, "attn": "flash_attention_2"}
{"key": "llamamoe", "main": true, "name": "LLaMA-MoE-v1-3.5B", "abbr": "LL1", "type": "causal", "num_params": 6.74, "num_layers": 32, "num_experts": 16, "top_k": 4, "attn": "eager"}
{"key": "llamamoes", "main": false, "name": "LLaMA-MoE-v1-3.5B-SFT", "abbr": "LL1-S", "type": "causal", "num_params": 6.74, "num_layers": 32, "num_experts": 16, "top_k": 4, "attn": "eager"}
{"key": "olmoe", "main": true, "name": "OLMoE-1B-7B-0125", "abbr": "OL", "type": "causal", "num_params": 6.92, "num_layers": 16, "num_experts": 64, "top_k": 8, "attn": "flash_attention_2"}
{"key": "olmoesft", "main": false, "name": "OLMoE-1B-7B-0125-SFT", "abbr": "OL-S", "type": "causal", "num_params": 6.92, "num_layers": 16, "num_experts": 64, "top_k": 8, "attn": "flash_attention_2"}
{"key": "olmoedpo", "main": false, "name": "OLMoE-1B-7B-0125-DPO", "abbr": "OL-D", "type": "causal", "num_params": 6.92, "num_layers": 16, "num_experts": 64, "top_k": 8, "attn": "flash_attention_2"}
{"key": "olmoeins", "main": false, "name": "OLMoE-1B-7B-0125-Instruct", "abbr": "OL-I", "type": "causal", "num_params": 6.92, "num_layers": 16, "num_experts": 64, "top_k": 8, "attn": "flash_attention_2"}
{"key": "switch", "main": true, "name": "SwitchTransformers-Base-128", "abbr": "ST", "type": "seq2seq", "num_params": 7.42, "num_layers": 24, "num_experts": 128, "top_k": 1, "attn": "eager"}
{"key": "llamamoe2", "main": true, "name": "LLaMA-MoE-v2-3.8B", "abbr": "LL2", "type": "causal", "num_params": 8.03, "num_layers": 32, "num_experts": 8, "top_k": 2, "attn": "flash_attention_2"}
{"key": "llamamoe2s", "main": false, "name": "LLaMA-MoE-v2-3.8B-Residual", "abbr": "LLR", "type": "causal", "num_params": 8.03, "num_layers": 32, "num_experts": 7, "top_k": 1, "attn": "flash_attention_2"}
{"key": "jetmoe", "main": true, "name": "JetMoE-8B", "abbr": "JT", "type": "causal", "num_params": 8.52, "num_layers": 24, "num_experts": 8, "top_k": 2, "attn": "flash_attention_2"}
{"key": "jetmoesft", "main": false, "name": "JetMoE-8B-SFT", "abbr": "JT-S", "type": "causal", "num_params": 8.52, "num_layers": 24, "num_experts": 8, "top_k": 2, "attn": "flash_attention_2"}
{"key": "jetmoechat", "main": false, "name": "JetMoE-8B-Chat", "abbr": "JT-C", "type": "causal", "num_params": 8.52, "num_layers": 24, "num_experts": 8, "top_k": 2, "attn": "flash_attention_2"}
{"key": "openmoe", "main": true, "name": "OpenMoE-8B", "abbr": "OP", "type": "causal", "num_params": 11.86, "num_layers": 24, "num_experts": 32, "top_k": 2, "attn": "eager"}
{"key": "minicpm", "main": true, "name": "MiniCPM-MoE-8x2B", "abbr": "MC", "type": "causal", "num_params": 13.87, "num_layers": 40, "num_experts": 8, "top_k": 2, "attn": "flash_attention_2"}
{"key": "qwen", "main": true, "name": "Qwen1.5-MoE-A2.7B", "abbr": "QW1", "type": "causal", "num_params": 14.32, "num_layers": 24, "num_experts": 60, "top_k": 4, "attn": "flash_attention_2"}
{"key": "deepseek2", "main": true, "name": "DeepSeek-V2-Lite", "abbr": "DS2", "type": "causal", "num_params": 15.71, "num_layers": 27, "num_experts": 64, "top_k": 6, "attn": "flash_attention_2"}
{"key": "deepseek", "main": true, "name": "DeepSeekMoE", "abbr": "DS1", "type": "causal", "num_params": 16.38, "num_layers": 28, "num_experts": 64, "top_k": 6, "attn": "flash_attention_2"}
{"key": "xverse", "main": true, "name": "XVERSE-MoE-A4.2B", "abbr": "XV", "type": "causal", "num_params": 25.78, "num_layers": 28, "num_experts": 64, "top_k": 6, "attn": "flash_attention_2"}
{"key": "qwen3", "main": true, "name": "Qwen3-30B-A3B", "abbr": "QW3", "type": "causal", "num_params": 30.53, "num_layers": 48, "num_experts": 128, "top_k": 8, "attn": "flash_attention_2"}
{"key": "yuan", "main": true, "name": "Yuan2.0-M32", "abbr": "Y2", "type": "causal", "num_params": 39.94, "num_layers": 24, "num_experts": 32, "top_k": 2, "attn": "flash_attention_2"}
{"key": "phi", "main": true, "name": "Phi-3.5-MoE", "abbr": "PH", "type": "causal", "num_params": 41.87, "num_layers": 32, "num_experts": 16, "top_k": 2, "attn": "flash_attention_2"}
{"key": "grin", "main": true, "name": "GRIN-MoE", "abbr": "GR", "type": "causal", "num_params": 41.87, "num_layers": 32, "num_experts": 16, "top_k": 2, "attn": "flash_attention_2"}
{"key": "mixtral", "main": true, "name": "Mixtral-8x7B-v0.1", "abbr": "MX", "type": "causal", "num_params": 46.7, "num_layers": 32, "num_experts": 8, "top_k": 2, "attn": "flash_attention_2"}
{"key": "jamba", "main": true, "name": "Jamba-Mini-1.6", "abbr": "JB", "type": "causal", "num_params": 51.57, "num_layers": 32, "num_experts": 16, "top_k": 2, "attn": "flash_attention_2"}
{"key": "nllb", "main": true, "name": "NLLB-MoE-54B", "abbr": "NL", "type": "seq2seq", "num_params": 54.5, "num_layers": 48, "num_experts": 128, "top_k": 2, "attn": "eager"}
{"key": "qwen2", "main": true, "name": "Qwen2-57B-A14B", "abbr": "QW2", "type": "causal", "num_params": 57.41, "num_layers": 28, "num_experts": 64, "top_k": 8, "attn": "flash_attention_2"}
